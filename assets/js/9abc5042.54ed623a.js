"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[144],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>c});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var o=n.createContext({}),p=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(o.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,r=e.originalType,o=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=p(a),g=i,c=u["".concat(o,".").concat(g)]||u[g]||m[g]||r;return a?n.createElement(c,s(s({ref:t},d),{},{components:a})):n.createElement(c,s({ref:t},d))}));function c(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=a.length,s=new Array(r);s[0]=g;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l[u]="string"==typeof e?e:i,s[1]=l;for(var p=2;p<r;p++)s[p]=a[p];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},3605:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>s,default:()=>m,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var n=a(7462),i=(a(7294),a(3905));const r={slug:"unsupervised data",title:"UDA - Unsupervised Data Augmentation",tags:["papers","deeplearning"],date:new Date("2019-08-20T00:00:00.000Z")},s=void 0,l={permalink:"/unsupervised data",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/UDA/index.md",source:"@site/blog/UDA/index.md",title:"UDA - Unsupervised Data Augmentation",description:"I look into a paper that introduces a fresh perspective on the role of advanced data augmentation methods in semi-supervised learning, showcasing remarkable results across various language and vision tasks. I show the key findings and dive into code examples that highlight the power of these techniques",date:"2019-08-20T00:00:00.000Z",formattedDate:"August 20, 2019",tags:[{label:"papers",permalink:"/tags/papers"},{label:"deeplearning",permalink:"/tags/deeplearning"}],readingTime:4.405,hasTruncateMarker:!0,authors:[],frontMatter:{slug:"unsupervised data",title:"UDA - Unsupervised Data Augmentation",tags:["papers","deeplearning"],date:"2019-08-20T00:00:00.000Z"},prevItem:{title:"IWild Cam 2019",permalink:"/iwild cam 2019"}},o={authorsImageUrls:[]},p=[{value:"Key Ideas and Findings",id:"key-ideas-and-findings",level:3},{value:"Key Results",id:"key-results",level:3},{value:"Components",id:"components",level:2},{value:"Loss Function",id:"loss-function",level:3},{value:"Implementation of KL-divergence",id:"implementation-of-kl-divergence",level:3},{value:"Augmentation Strategies",id:"augmentation-strategies",level:2},{value:"Additional Training Techniques",id:"additional-training-techniques",level:2},{value:"Training Signal Annealing",id:"training-signal-annealing",level:3},{value:"Implementation of TSA",id:"implementation-of-tsa",level:3},{value:"Sharpening Predictions",id:"sharpening-predictions",level:3},{value:"Implementation",id:"implementation",level:3},{value:"Domain-relevance Data filtering",id:"domain-relevance-data-filtering",level:3},{value:"Comparison to current approaches",id:"comparison-to-current-approaches",level:3}],d={toc:p},u="wrapper";function m(e){let{components:t,...r}=e;return(0,i.kt)(u,(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"I look into a paper that introduces a fresh perspective on the role of advanced data augmentation methods in semi-supervised learning, showcasing remarkable results across various language and vision tasks. I show the key findings and dive into code examples that highlight the power of these techniques"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/1904.12848"},"[Paper]")," ",(0,i.kt)("a",{parentName:"p",href:"https://ai.googleblog.com/2019/07/advancing-semi-supervised-learning-with.html"},"[Blog Post]")),(0,i.kt)("p",null,"All code snippets taken from this ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/google-research/uda"},"repository")),(0,i.kt)("h3",{id:"key-ideas-and-findings"},"Key Ideas and Findings"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Improving classification models with unlabeled data, data augmentation and semi-supervised learning. ")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Combining both labelled and unlabeled and using a custom loss function you can train a classifier for both computer vision and nlp problems.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Matches and outperforms supervised learning approaches with only a fraction of the data. "))),(0,i.kt)("h3",{id:"key-results"},"Key Results"),(0,i.kt)("p",null,"1 - Using CIFAR-10 with 4k examples, UDA achieves an error rate of 5.27, matching the performance of a fully supervised model that uses 50k examples"),(0,i.kt)("p",null,"2 - UDA achieves a new state-of-the-art error rate with a more than 45% reduction in error rate compared to the previous best semi-supervised result."),(0,i.kt)("p",null,"3 - On SVHN, UDA achieves an error rate of 2.46 with only 1k labeled examples, matching the performance of the fully supervised model trained with ~70k labeled examples."),(0,i.kt)("h2",{id:"components"},"Components"),(0,i.kt)("h3",{id:"loss-function"},"Loss Function"),(0,i.kt)("p",null,"This loss function is calculated by combining two loss functions one for the supervised part of the data (labelled) and one for the unsupervised part of the data (UDA). There is also a weighting factor ",(0,i.kt)("strong",{parentName:"p"},"\u03bb")," applied to the UDA loss function, researchers set ",(0,i.kt)("strong",{parentName:"p"},"\u03bb")," to 1 for most of their experiments."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Supervised Loss (Labelled Data)-"),"  Cross entropy"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Unsupervised Consistency Loss (Unlabelled Data)-")," more specifically KL divergence, it is calculated between predicted distributions on the unlabeled examples and unlabeled augmented example."),(0,i.kt)("h3",{id:"implementation-of-kl-divergence"},"Implementation of KL-divergence"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python",metastring:'title="uda/image/main.py"',title:'"uda/image/main.py"'},"# q_logits are the augmented logits \ndef _kl_divergence_with_logits(p_logits, q_logits):\n    p = tf.nn.softmax(p_logits)\n    log_p = tf.nn.log_softmax(p_logits)\n    log_q = tf.nn.log_softmax(q_logits)\n    kl = tf.reduce_sum(p * (log_p - log_q), -1)\nreturn kl\n\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"loss function",src:a(2125).Z,width:"986",height:"400"})),(0,i.kt)("h2",{id:"augmentation-strategies"},"Augmentation Strategies"),(0,i.kt)("p",null,"Image augmentation was done using  ",(0,i.kt)("strong",{parentName:"p"},"AutoAugment")," ",(0,i.kt)("a",{parentName:"p",href:"https://ai.googleblog.com/2018/06/improving-deep-learning-performance.html"},"[Paper]")," ",(0,i.kt)("a",{parentName:"p",href:"https://towardsdatascience.com/how-to-improve-your-image-classifier-with-googles-autoaugment-77643f0be0c9"},"[Medium]")," and ",(0,i.kt)("strong",{parentName:"p"},"Cutout")," ",(0,i.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/1708.04552"},"[Paper]")," was also used for experiments with CIFAR-10 and SVHN. It is noted that there is a trade off between having diverse augmented training examples and at the same time keeping the ground truth label matched. Many augmented samples where created for one ground truth and were all generated offline before training."),(0,i.kt)("p",null,"Text augmentation was done using back translation and a process called TF-IDF."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"UDA Data augmentation",src:a(4599).Z,width:"907",height:"376"})),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Results from ablation study on different augmentation strategies")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"augmentation results",src:a(3007).Z,width:"487",height:"288"})),(0,i.kt)("h2",{id:"additional-training-techniques"},"Additional Training Techniques"),(0,i.kt)("h3",{id:"training-signal-annealing"},"Training Signal Annealing"),(0,i.kt)("p",null,"By training on sch a small number of training samples there was a risk of the model overfitting to the labelled data. To negate that researches used (TSA) with the idea being to ",(0,i.kt)("em",{parentName:"p"},"gradually release training signals of the labeled data without overfitting as the model is trained on more and more unlabeled examples.")),(0,i.kt)("p",null,"When the probability of the correct category is higher the some threshold then that example is removed from the loss calculation. This threshold prevents the model from over-training on examples it is already confident on."),(0,i.kt)("p",null,"Three threshold schedules were suggested with the decision on which to use dependant on the different ratios of labeled and unlabeled data."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"log-schedule")," where threshold is increased most rapidly at the beginning of training. Used when the model is ",(0,i.kt)("strong",{parentName:"p"},"less")," likely to overfit because of abundance of labeled examples or effective regularizations in the model."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"exp-schedule")," where threshold is increased most rapidly at the end of training. Used when the problem is ",(0,i.kt)("strong",{parentName:"p"},"more")," likely to overfit because of a relatively easy problem or the number of training examples is limited. The supervising signal get mostly released by the end of training."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"linear-schedule")," where the threshold is linearly increased while training."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"training signal schedules",src:a(8242).Z,width:"542",height:"378"})),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Results from ablation study on different TSA schedules")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"training signal results",src:a(5953).Z,width:"483",height:"254"})),(0,i.kt)("h3",{id:"implementation-of-tsa"},"Implementation of TSA"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python",metastring:'title="uda/image/main.py"',title:'"uda/image/main.py"'},'\ndef get_tsa_threshold(schedule, global_step, num_train_steps, start, end):\n  step_ratio = tf.to_float(global_step) / tf.to_float(num_train_steps)\n  if schedule == "linear_schedule":\n    coeff = step_ratio\n  elif schedule == "exp_schedule":\n    scale = 5\n    # [exp(-5), exp(0)] = [1e-2, 1]\n    coeff = tf.exp((step_ratio - 1) * scale)\n  elif schedule == "log_schedule":\n    scale = 5\n    # [1 - exp(0), 1 - exp(-5)] = [0, 0.99]\n    coeff = 1 - tf.exp((-step_ratio) * scale)\n  return coeff * (end - start) + start\n\n# Usage \n# line 258\n eff_train_prob_threshold = get_tsa_threshold(\n      FLAGS.tsa, global_step, FLAGS.train_steps,\n      tsa_start, end=1)\n\n# line 276\n larger_than_threshold = tf.greater(\n      correct_label_probs, eff_train_prob_threshold)\n\n')),(0,i.kt)("h3",{id:"sharpening-predictions"},"Sharpening Predictions"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Confidence-based masking")," - If the predictions on the labelled data is below some confidence threshold then these predictions are removed from the final loss calculation, leaving only predictions with the highest confidence probabilities.")),(0,i.kt)("h3",{id:"implementation"},"Implementation"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python",metastring:'title="uda/image/main.py"',title:'"uda/image/main.py"'},'\nori_prob = tf.nn.softmax(ori_logits, axis=-1)\nlargest_prob = tf.reduce_max(ori_prob, axis=-1)\nloss_mask = tf.cast(tf.greater(largest_prob, FLAGS.uda_confidence_thresh), tf.float32)\n# metric_dict["unsup/high_prob_ratio"] = tf.reduce_mean(loss_mask)\nloss_mask = tf.stop_gradient(loss_mask)\naug_loss = aug_loss * loss_mask\n# metric_dict["unsup/high_prob_loss"] = tf.reduce_mean(aug_loss)\n\n')),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("strong",{parentName:"p"},"Entropy minimization"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("strong",{parentName:"p"},"Softmax temperature controlling")))),(0,i.kt)("h3",{id:"domain-relevance-data-filtering"},"Domain-relevance Data filtering"),(0,i.kt)("p",null,"If the class distribution between the labeled and unlabeled data sets are unmatched it can hurt the performance of the model. To try and match the class distributions between the labeled and unlabeled data a model was trained on the labeled samples and used to infer the unlabeled samples class. Examples that the model was most confident on where then used for training."),(0,i.kt)("h3",{id:"comparison-to-current-approaches"},"Comparison to current approaches"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"compare other apporaches",src:a(3677).Z,width:"640",height:"309"})))}m.isMDXComponent=!0},2125:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/4-Figure1-1-bc83060a7524b291a4127fd3157f0543.png"},8242:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/5-Figure2-1-03f74b2cdc9f1037b5e679c30d5ae154.png"},4599:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/UDA-augmentation-d194301c61c4f56a297127d37fe37abb.png"},3007:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/aug-results-f3a15f822c4d3adfff775d7dad6020ce.png"},3677:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/compare-results-50b86f6e7b80606b6bc6e0e41eab5f47.png"},5953:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tsa-results-ee88fe7effa7e1d853626ff82ae1ed36.png"}}]);